{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.1\n",
      "Select a dataset:\n",
      "1: Iris dataset\n",
      "2: Wine dataset\n",
      "3: California Housing dataset\n",
      "4: Load dataset from URL\n",
      "5: Load dataset from local file\n",
      "Enter the number of the option you want to use: 2\n",
      "Choose strategy for numerical missing values:\n",
      "1: Mean\n",
      "2: Median\n",
      "3: Mode\n",
      "4: Fill with -1\n",
      "Enter your choice: 3\n",
      "Choose strategy for categorical missing values:\n",
      "1: Most frequent\n",
      "2: Fill with 'missing'\n",
      "Enter your choice: 1\n",
      "Would you like to scale numerical features? (yes/no): yes\n",
      "Scaling features...\n",
      "Choose scaling method (1 for StandardScaler, 2 for MinMaxScaler): 2\n",
      "\n",
      "Correlation with target column:\n",
      "1: alcohol - 0.33\n",
      "2: malic_acid - 0.44\n",
      "3: ash - 0.05\n",
      "4: alcalinity_of_ash - 0.52\n",
      "5: magnesium - 0.21\n",
      "6: total_phenols - 0.72\n",
      "7: flavanoids - 0.85\n",
      "8: nonflavanoid_phenols - 0.49\n",
      "9: proanthocyanins - 0.50\n",
      "10: color_intensity - 0.27\n",
      "11: hue - 0.62\n",
      "12: od280/od315_of_diluted_wines - 0.79\n",
      "13: proline - 0.63\n",
      "\n",
      "Press 'S' to skip or enter the numbers (comma-separated) of columns to drop: 11\n",
      "Dropped columns: ['hue']\n",
      "\n",
      "Available models for classification:\n",
      "1: RandomForestClassifier\n",
      "2: XGBoostClassifier\n",
      "3: LogisticRegression\n",
      "4: KNeighborsClassifier\n",
      "Select model: 2\n",
      "Model Accuracy: 98.15%\n",
      "Confusion Matrix:\n",
      " [[19  0  0]\n",
      " [ 0 21  0]\n",
      " [ 0  1 13]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.95      1.00      0.98        21\n",
      "           2       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.98        54\n",
      "   macro avg       0.98      0.98      0.98        54\n",
      "weighted avg       0.98      0.98      0.98        54\n",
      "\n",
      "Would you like to save the model? (yes/no): no\n",
      "Would you like to save the predictions? (yes/no): no\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, r2_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "\n",
    "# 1. Dataset Input Options\n",
    "def load_dataset(choice):\n",
    "    \"\"\"Load dataset from a variety of sources like URL, local file, or built-in datasets.\"\"\"\n",
    "    if choice == '1':\n",
    "        from sklearn.datasets import load_iris\n",
    "        data = load_iris(as_frame=True)\n",
    "        df = pd.concat([data.data, data.target.rename('target')], axis=1)\n",
    "        return df, detect_task_type(df)\n",
    "    elif choice == '2':\n",
    "        from sklearn.datasets import load_wine\n",
    "        data = load_wine(as_frame=True)\n",
    "        df = pd.concat([data.data, data.target.rename('target')], axis=1)\n",
    "        return df, detect_task_type(df)\n",
    "    elif choice == '3':\n",
    "        from sklearn.datasets import fetch_california_housing\n",
    "        data = fetch_california_housing(as_frame=True)\n",
    "        df = pd.concat([data.data, data.target.rename('target')], axis=1)\n",
    "        return df, detect_task_type(df)\n",
    "    elif choice == '4':\n",
    "        url = input(\"Enter the URL to the dataset: \")\n",
    "        df = pd.read_csv(url)\n",
    "        return df, detect_task_type(df)\n",
    "    elif choice == '5':\n",
    "        file_path = input(\"Enter the path to the dataset file: \")\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df, detect_task_type(df)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset choice\")\n",
    "\n",
    "# 2. Data Preprocessing\n",
    "def preprocess_data(X, strategy_num, strategy_cat, scale_option):\n",
    "    \"\"\"Impute missing values, encode categorical data, and scale numeric features.\"\"\"\n",
    "    num_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    cat_cols = X.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "    # Impute missing values for numerical columns\n",
    "    if strategy_num == '1':\n",
    "        imputer_num = SimpleImputer(strategy='mean')\n",
    "    elif strategy_num == '2':\n",
    "        imputer_num = SimpleImputer(strategy='median')\n",
    "    elif strategy_num == '3':\n",
    "        imputer_num = SimpleImputer(strategy='most_frequent')\n",
    "    elif strategy_num == '4':\n",
    "        imputer_num = SimpleImputer(strategy='constant', fill_value=-1)\n",
    "    X[num_cols] = imputer_num.fit_transform(X[num_cols])\n",
    "\n",
    "    # Impute missing values for categorical columns\n",
    "    if len(cat_cols) > 0:\n",
    "        if strategy_cat == '1':\n",
    "            imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "        elif strategy_cat == '2':\n",
    "            imputer_cat = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "        X[cat_cols] = imputer_cat.fit_transform(X[cat_cols])\n",
    "\n",
    "    # Encode categorical columns\n",
    "    encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    X_encoded = pd.DataFrame(encoder.fit_transform(X[cat_cols]))\n",
    "    X_encoded.columns = encoder.get_feature_names(cat_cols)\n",
    "    X = pd.concat([X[num_cols], X_encoded], axis=1)\n",
    "\n",
    "    # Scale numeric features\n",
    "    if scale_option == 'yes':\n",
    "        print(\"Scaling features...\")\n",
    "        scaler = StandardScaler() if input(\"Choose scaling method (1 for StandardScaler, 2 for MinMaxScaler): \") == '1' else MinMaxScaler()\n",
    "        X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "\n",
    "    return X\n",
    "\n",
    "# 3. Target Detection\n",
    "def detect_task_type(df):\n",
    "    \"\"\"Detect if the task is classification or regression based on the target column.\"\"\"\n",
    "    target_column = detect_target_column(df)\n",
    "    if df[target_column].dtype in ['float64', 'int64'] and df[target_column].nunique() > 10:\n",
    "        return \"regression\"\n",
    "    else:\n",
    "        return \"classification\"\n",
    "\n",
    "def detect_target_column(df):\n",
    "    \"\"\"Identify the target column in the dataset.\"\"\"\n",
    "    if 'target' not in df.columns:\n",
    "        print(\"No explicitly named 'target' column found. Assuming the last column on the right is the target variable.\")\n",
    "        return df.columns[-1]\n",
    "    return 'target'\n",
    "\n",
    "# 4. Feature Engineering\n",
    "def feature_selection(X, y):\n",
    "    \"\"\"Allow the user to select features based on correlation or importance scores.\"\"\"\n",
    "\n",
    "    # Calculate correlation of each feature with the target variable\n",
    "    corr_matrix = X.copy()\n",
    "    corr_matrix['target'] = y\n",
    "    corr = corr_matrix.corr().abs()\n",
    "\n",
    "    # Display correlation with target column, excluding the target column itself\n",
    "    print(\"\\nCorrelation with target column:\")\n",
    "    feature_list = []\n",
    "    for idx, col in enumerate(corr.columns[:-1]):  # Exclude target column from the printout\n",
    "        print(f\"{idx + 1}: {col} - {corr[col]['target']:.2f}\")\n",
    "        feature_list.append(col)\n",
    "\n",
    "    # Ask user which columns to drop based on correlation\n",
    "    drop_columns_input = input(\"\\nPress 'S' to skip or enter the numbers (comma-separated) of columns to drop: \")\n",
    "\n",
    "    if drop_columns_input.strip().lower() == 's':\n",
    "        print(\"Skipping feature selection.\")\n",
    "        return X\n",
    "\n",
    "    # If user enters a comma-separated list of numbers\n",
    "    if drop_columns_input.strip():\n",
    "        drop_indices = drop_columns_input.split(',')\n",
    "        drop_columns = [feature_list[int(idx.strip()) - 1] for idx in drop_indices if idx.strip().isdigit()]\n",
    "\n",
    "        if drop_columns:\n",
    "            X = X.drop(columns=drop_columns)\n",
    "            print(f\"Dropped columns: {drop_columns}\")\n",
    "\n",
    "    return X\n",
    "\n",
    "# 5. Model Selection\n",
    "def select_model(task_type):\n",
    "    \"\"\"Allow user to select and configure models.\"\"\"\n",
    "    if task_type == \"classification\":\n",
    "        print(\"\\nAvailable models for classification:\")\n",
    "        print(\"1: RandomForestClassifier\\n2: XGBoostClassifier\\n3: LogisticRegression\\n4: KNeighborsClassifier\")\n",
    "        model_choice = input(\"Select model: \")\n",
    "        return {\n",
    "            '1': RandomForestClassifier(random_state=42),\n",
    "            '2': XGBClassifier(random_state=42),\n",
    "            '3': LogisticRegression(max_iter=200),\n",
    "            '4': KNeighborsClassifier()\n",
    "        }[model_choice]\n",
    "    elif task_type == \"regression\":\n",
    "        print(\"\\nAvailable models for regression:\")\n",
    "        print(\"1: RandomForestRegressor\\n2: XGBoostRegressor\\n3: LinearRegression\\n4: DecisionTreeRegressor\")\n",
    "        model_choice = input(\"Select model: \")\n",
    "        return {\n",
    "            '1': RandomForestRegressor(random_state=42),\n",
    "            '2': XGBRegressor(random_state=42),\n",
    "            '3': LinearRegression(),\n",
    "            '4': DecisionTreeRegressor()\n",
    "        }[model_choice]\n",
    "\n",
    "# 6. Model Evaluation\n",
    "def evaluate_model(model, task_type, X_test, y_test, y_pred):\n",
    "    \"\"\"Evaluate model based on the task type.\"\"\"\n",
    "    if task_type == \"classification\":\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    elif task_type == \"regression\":\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "        print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "        print(f\"R² Score: {r2:.2f}\")\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    print(\"Select a dataset:\")\n",
    "    print(\"1: Iris dataset\\n2: Wine dataset\\n3: California Housing dataset\\n4: Load dataset from URL\\n5: Load dataset from local file\")\n",
    "    choice = input(\"Enter the number of the option you want to use: \")\n",
    "    df, task_type = load_dataset(choice)\n",
    "\n",
    "    # Preprocessing\n",
    "    X = df.drop(columns=[detect_target_column(df)])\n",
    "    y = df[detect_target_column(df)]\n",
    "    print(\"Choose strategy for numerical missing values:\\n1: Mean\\n2: Median\\n3: Mode\\n4: Fill with -1\")\n",
    "    strategy_num = input(\"Enter your choice: \")\n",
    "    print(\"Choose strategy for categorical missing values:\\n1: Most frequent\\n2: Fill with 'missing'\")\n",
    "    strategy_cat = input(\"Enter your choice: \")\n",
    "    scale_option = input(\"Would you like to scale numerical features? (yes/no): \")\n",
    "    X_cleaned = preprocess_data(X, strategy_num, strategy_cat, scale_option)\n",
    "\n",
    "    # Feature Selection\n",
    "    X_cleaned = feature_selection(X_cleaned, y)\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Model Selection\n",
    "    model = select_model(task_type)\n",
    "\n",
    "    # Model Training\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Model Evaluation\n",
    "    evaluate_model(model, task_type, X_test, y_test, y_pred)\n",
    "\n",
    "    # Save Model\n",
    "    if input(\"Would you like to save the model? (yes/no): \").lower() == 'yes':\n",
    "        with open('trained_model.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        print(\"Model saved as 'trained_model.pkl'.\")\n",
    "\n",
    "    # Save Predictions\n",
    "    if input(\"Would you like to save the predictions? (yes/no): \").lower() == 'yes':\n",
    "        predictions_df = pd.DataFrame({\"Actual\": y_test.values, \"Predicted\": y_pred})\n",
    "        predictions_df.to_csv(\"predictions.csv\", index=False)\n",
    "        print(\"Predictions saved as 'predictions.csv'.\")\n",
    "\n",
    "# Run the main program\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
